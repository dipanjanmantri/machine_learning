# -*- coding: utf-8 -*-
"""04_pytorch_custom_datasets_video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9BIIh81kR4hvTe4DUy-fz-JWLz_AaGk
"""

# Importing PyTorch and setting up device agnostic code
import torch
from torch import nn

torch.__version__

# Setup device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

device

"""## Get data"""

import requests
import zipfile
from pathlib import Path

# Setup path to a data folder
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi"

# If the image folder does not exist, download it and prepare it.....
if image_path.is_dir():
  print(f"Image path {image_path} already exists")
else:
  print("Creating....")
  image_path.mkdir(parents=True, exist_ok=True)

# Download pizza, steak and sushi data
with open(data_path / "pizza_steak_sushi.zip","wb") as f:
  request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip")
  print("Donnloading pizza, steak and sushi data")
  f.write(request.content)


# Unzip the file
with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
  print("unziping the content")
  zip_ref.extractall(image_path)

image_path

"""## Data preparation and exploration

"""

import os
def walk_through_dir(dir_path):
  # Generates information from the directory tree structures
  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'")

walk_through_dir(image_path)

# Setup train and test paths
train_dir = image_path / "train"
test_dir = image_path / "test"

train_dir, test_dir

# /content/data/pizza_steak_sushi  (imagepath)

# list(image_path.glob("*/*/*.jpg"))

"""## Visualize an image"""

import random
from PIL import Image

# Set the seed
# random.seed(42)

# 1. Get all image paths
image_path_list = list(image_path.glob("*/*/*.jpg"))

# 2. Pick a random image path
random_image_path = random.choice(image_path_list)

# 3. Get image class from the path name
image_class = random_image_path.parent.stem

# random_image_path, random_image_path.parent, random_image_path.parent.stem

# 4. Open image
img = Image.open(random_image_path)

# 5. Print metadata
print(f"Random image path: {random_image_path}")
print(f"Image class: {image_class}")
print(f"Image height: {img.height}")
print(f"Image width: {img.width}")
img



# Try to visualize image with matplotlib
import numpy as np
import matplotlib.pyplot as plt

# Turn the image to an array
img_as_array = np.asarray(img)

# Plot the image with plt
plt.figure(figsize=(10,7))
plt.imshow(img_as_array)
plt.title(f"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color channels]")
plt.axis(False)

img_as_array

## Transform data to tensors
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Transforming data with torchvision.transforms
# Takes a list as input
data_transform = transforms.Compose([
    # Resize the images to 64x64
    transforms.Resize(size=(64,64)),
    # Flip the images randomly on the horizontal
    transforms.RandomHorizontalFlip(p=0.5),
    # Turn the image into torch.Tensor
    transforms.ToTensor()
])

data_transform(img).shape, data_transform(img).dtype

fig, ax = plt.subplots(1,2)
fig

def plot_transformed_images(image_paths: list, transform, n=3, seed=None):
  if seed:
    random.seed(seed)
  random_image_paths = random.sample(image_paths, k=n)
  for image_path in random_image_paths:
    with Image.open(image_path) as f:
      fig, ax = plt.subplots(nrows=1, ncols=2)
      ax[0].imshow(f)
      ax[0].set_title(f"Original shape: \n{f.size}")
      ax[0].axis(False)

      # Transform and plot target image
      transformed_image = transform(f).permute(1,2,0) # permute swaps the order of the axes, (C, H, W) -> (H, W, C)
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed shape: \n{transformed_image.size}")
      ax[1].axis(False)


      fig.suptitle(f"Class: {image_path.parent.stem}", fontsize=16)


plot_transformed_images(image_paths=image_path_list,
                        transform=data_transform,
                        n=3,
                        seed=None)



image_path_list, data_transform

# Use ImageFolder to create datasets
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir,
                                  transform=data_transform, # transform for the data
                                  target_transform=None) # transform for the label/target, we dont need to set now

test_data = datasets.ImageFolder(root=test_dir,
                                  transform=data_transform # transform for the data
                                ) # transform for the label/target, we dont need to set now

train_data, test_data

# Get class names as list
class_names = train_data.classes
class_names

# Get class names as dict
class_names = train_data.class_to_idx
class_names

# Check the lengths of our dataset
len(train_data), len(test_data)

train_data.samples[:10], train_data.targets[:10]

# Index on the train_data to get a single image and label
img, label = train_data[0][0], train_data[0][1]
print(f"Image tensor:\n {img}")
print(f"Image shape:\n {img.shape}")
print(f"Image datatype:\n {img.dtype}")
print(f"Image label:\n {label}")
print(f"Label datatype:\n {type(label)}")

import torch, pathlib, os
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import Tuple, Dict, List

# Instance of torchvision.datasets.ImageFolder()
train_data.classes, train_data.class_to_idx

# Rearrange the order dimensions (matplotlib likes color channels last)
img_permute = img.permute(1,2,0)

# Print out different shapes
print(f"Original shape: {img.shape} -> [color_channels, height, width]")
print(f"Permute shape: {img_permute.shape} -> [height, width, color_channels]")

# Plot the image
plt.figure(figsize=(10,7))
plt.imshow(img_permute)
plt.axis(False)
# plt.title(class_names[label], fontsize=14)

import os
os.cpu_count()

# Turn loaded images into DataLoader
# Dataloader converts loaded images to iterables so that we can customize the batch size
# Turn train and test datasets to dataloaders
from torch.utils.data import DataLoader
import os

BATCH_SIZE=32
train_dataloader=DataLoader(dataset=train_data,
                            batch_size=BATCH_SIZE,
                            num_workers=os.cpu_count(), # num_workers, more the better, number of cpu calls
                            shuffle=True)

test_dataloader=DataLoader(dataset=test_data,
                            batch_size=BATCH_SIZE,
                            num_workers=os.cpu_count(),
                            shuffle=True)

train_dataloader, test_dataloader

len(train_dataloader), len(test_dataloader)

img, label = next(iter(train_dataloader))
print(f"Image shape: {img.shape} -> [batch-size, color_channels, height, width]")
print(f"Image shape: {label.shape}")

next(iter(train_dataloader))

"""## Loading image data with a custom dataset"""

# list(os.scandir(target_directory)), os.scandir(target_directory), target_directory

# [entry.name for entry in list(os.scandir(target_directory))], sorted([entry.name for entry in list(os.scandir(target_directory))])

# Creating a helper functions to get class_names

# Setup path for target directory
target_directory = train_dir

# Get the class names from the target directory
class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])
class_names_found

def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:
  # 1. Get the class names by scanning the target directory
  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())

  # 2. Raise an error if class_names could not be found
  if not classes:
    raise FileNotFoundError(f"Could not find any classes{directory}")

  # 3. Create a dictionary of index labels (computers prefer numbers rather than strings as labels)
  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}
  return classes, class_to_idx

"""## Create a custom dataset to replicate ImageFolder....."""

# 0. Write a custom dataset class
from torch.utils.data import Dataset

# 1. Subclass torch.utils.data.Dataset
class ImageFolderCustom(Dataset):
  # 2. Initialize our custom dataset
  def __init__(self,
               targ_dir: str,
               transform=None):
    # 3. Create class attributes

    # Get all of the image paths
    self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg"))

    # Setup transform
    self.transform = transform

    # Create classes and class_to_idx attributes
    self.classes, self.class_to_idx = find_classes(targ_dir)

  # 4. Create a function to load images
  def load_image(self, index: int) -> Image.Image:
    "Opens an image via a path and returns it."
    image_path = self.paths[index]
    return Image.open(image_path)

  # 5. Overwrite __len__()
  def __len__(self) -> int:
    "Returns the total number of samples."
    return len(self.paths)

  # 6. Overwrite __getitem__() method to return a particular sample
  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:
    "Returns one sample of data, data and label (X, y)."
    img = self.load_image(index)
    class_name = self.paths[index].parent.name # expects path in format: data_folder/class_name/image.jpg
    class_idx = self.class_to_idx[class_name]

    # Transform if necessary
    if self.transform:
      return self.transform(img), class_idx # return data, label (X, y)
    else:
      return img, class_idx # return untransformed image and label

find_classes(target_directory)

for k in list(os.scandir(target_directory)):
  print(k)
  print(k.name)

sorted(["sushi","steak","pizza"])

# Create a transform
from torchvision import transforms
train_transforms = transforms.Compose([
                                      transforms.Resize(size=(64, 64)),
                                      transforms.RandomHorizontalFlip(p=0.5),
                                      transforms.ToTensor()
])

test_transforms = transforms.Compose([
                                      transforms.Resize(size=(64, 64)),
                                      transforms.ToTensor()
])

# Test out ImageFolderCustom
train_data_custom = ImageFolderCustom(targ_dir=train_dir,
                                      transform=train_transforms)

test_data_custom = ImageFolderCustom(targ_dir=test_dir,
                                      transform=test_transforms)

train_data_custom, test_data_custom

len(train_data), len(train_data_custom)

len(test_data), len(test_data_custom)

train_data.classes, train_data_custom.classes

train_data.class_to_idx, train_data_custom.class_to_idx

# Check equality between ImageFolder and ImageFolderCustom datsets
print(train_data.classes == train_data_custom.classes)
print(train_data.class_to_idx == train_data_custom.class_to_idx)

print(test_data.classes == test_data_custom.classes)
print(test_data.class_to_idx == test_data_custom.class_to_idx)

import random
random.sample(range(5),k=2)

# 1. Create a function to display random images
def display_random_images(dataset: torch.utils.data.Dataset,
                          classes: List[str] = None,
                          n: int=10,
                          display_shape: bool = True,
                          seed: int = None):

  # 2. Adjust display if n is too high
  if n>10:
    n=10
    display_shape=False
    print(f"removing shape display")

  # 3. Set the random seed
  if seed:
    random.seed(seed)

  # 4. Get random sample indexes
  random_samples_idx = random.sample(range(len(dataset)), k=n)

  # 5. Setup plot
  plt.figure(figsize=(16,8))

  # 6. Loop through random indexes and plot them with matplotlib
  for i, targ_sample in enumerate(random_samples_idx):
    targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1] # [0] is the image and [1] is the label

    # 7. Adjust tensor dimensions for plotting
    targ_image_adjust = targ_image.permute(1,2,0) # (C, H, W) -> (H, W, C)

    # 8. Plot adjusted samples
    plt.subplot(1, n, i+1)
    plt.imshow(targ_image_adjust)
    plt.axis(False)

train_data

random.sample(range(len(train_data_custom)), k=10)

# Display random images from the ImageFolder
display_random_images(dataset=train_data,
                      classes=class_names,
                      n=10,
                      seed=None)

# Turn custom loaded images into DataLoader
from torch.utils.data import DataLoader
BATCH_SIZE=32
NUM_WORKERS = os.cpu_count()

train_dataloader_custom = DataLoader(dataset=train_data_custom,
                                     batch_size=BATCH_SIZE,
                                     num_workers=NUM_WORKERS,
                                     shuffle=True)

test_dataloader_custom = DataLoader(dataset=test_data_custom,
                                     batch_size=BATCH_SIZE,
                                     num_workers=NUM_WORKERS,
                                     shuffle=False
                                     )


train_dataloader_custom, test_dataloader_custom

# Get image and label from custom dataloder
img_custom, label_custom = next(iter(train_dataloader_custom))

# Print out the shapes
img_custom.shape, label_custom.shape

# Other forms of transforms (data augmentation)
# trivialaugment

from torchvision import transforms

train_transform = transforms.Compose(
    [
        transforms.Resize(size=(224,224)),
        transforms.TrivialAugmentWide(num_magnitude_bins=31),
        transforms.ToTensor()
    ]
)

test_transform = transforms.Compose(
    [
        transforms.Resize(size=(224,224)),
        transforms.ToTensor()
    ]
)

# Get image paths
image_path_list = list(image_path.glob("*/*/*.jpg"))
image_path_list[:10]

# Plot random transfomed images
plot_transformed_images(
    image_paths=image_path_list,
    transform=train_transform,
    n=3,
    seed=None
)

## Model 0: TinyVGG without data augmentation

# Create transforms and loading data for Model 0

# Create a transform
simple_transform = transforms.Compose(
    [
        transforms.Resize(size=(64,64)),
        transforms.ToTensor()
    ]
)

# Load and transform data
from torchvision import datasets

train_data_simple = datasets.ImageFolder(
    root=train_dir,
    transform=simple_transform
)

test_data_simple = datasets.ImageFolder(
    root=test_dir,
    transform=simple_transform
)

# Datasets -> DataLoaders
import os
from torch.utils.data import DataLoader

# Setup batch_size and num_workers
BATCH_SIZE=32
NUM_WORKERS=os.cpu_count()

# Create dataloaders
train_dataloader_simple = DataLoader(dataset=train_data_simple,
                                     batch_size=BATCH_SIZE,
                                     num_workers=NUM_WORKERS,
                                     shuffle=True)

test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                     batch_size=BATCH_SIZE,
                                     num_workers=NUM_WORKERS
                                    )

# Create TinyVGG model class
from torch import nn

class TinyVGG(nn.Module):
  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:
    super().__init__()
    self.conv_block_1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2) # default stride value is same as the kernel_size
    )

    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2) # default stride value is same as the kernel_size
    )

    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*13*13,
                  out_features=output_shape)
    )


  def forward(self, x):
    x = self.conv_block_1(x)
    # print(x.shape)
    x = self.conv_block_2(x)
    # print(x.shape)
    x = self.classifier(x)
    # print(x.shape)
    return x
    # second option
    # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # benefits from operator fusion and it improves the performance
                                                                      # as it computes everything in one line(best practice for speed up)

torch.manual_seed(42)
model_0 = TinyVGG(input_shape=3, # Number of color channels in our image data
                  hidden_units=10,
                  output_shape=len(class_names)).to(device)

model_0

## Try a forward pass on a single image to test our model

# Get a single image batch
image_batch, label_batch = next(iter(train_dataloader_custom))
image_batch.shape, label_batch.shape

# Try a forward pass
model_0(image_batch).to(device)

## Install torchinfo

!pip install torchinfo

from torchinfo import summary
summary(model_0, input_size=[1, 3, 64, 64]) # 1 is the batchsize, 3 is the colorchannels, 64 is the height, 64 is the width

"""## Create train and test loop functions"""

# Create a train step
import torch


def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               device=device):

  # Training mode
  model.train()

  # Setup train loss and train accuracy values
  train_loss, train_acc = 0, 0

  # Loop through the dataloader data batches
  for batch, (X, y) in enumerate(dataloader):


    # forward pass
    y_pred = model(X) # outputs model logits

    # calculate loss
    loss = loss_fn(y_pred, y)
    train_loss += loss.item()

    # optimizer zero grad
    optimizer.zero_grad()

    # loss backward
    loss.backward()

    # optimizer step
    optimizer.step()

    # calculate accuracy metric
    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
    train_acc += (y_pred_class==y).sum().item()/len(y_pred)

  # Calculate the average loss and accuracy per batch
  train_loss /= len(dataloader)
  train_acc /= len(dataloader)
  return train_loss, train_acc



# Create a test step

def test_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               device=device):

  # Eval mode
  model.eval()

  # setup the test loss and test accuracy values
  test_loss, test_acc = 0, 0

  with torch.inference_mode():
    for batch, (X, y) in enumerate(dataloader):
      X, y = X.to(device), y.to(device)

      # forward pass
      test_pred_logits = model(X)

      # calculate the loss
      loss = loss_fn(test_pred_logits, y)
      test_loss += loss.item()

      # calculate the accuracy
      test_pred_labels = test_pred_logits.argmax(dim=1)
      test_acc += ((test_pred_labels==y).sum().item()/len(test_pred_logits))

  # Get the average loss and accuracy per batch
  test_loss /= len(dataloader)
  test_acc /= len(dataloader)

  return test_loss, test_acc

from tqdm.auto import tqdm
def train(model: torch.nn.Module,
          train_dataloader,
          test_dataloader,
          optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
          epochs: int = 5,
          device=device):

  # Create empty results dictionary
  results = {
      "train_loss": [],
      "train_acc": [],
      "test_loss": [],
      "test_acc": []
  }

  # Looping through training and testing with epochs
  for epoch in tqdm(range(epochs)):
    train_loss, train_acc = train_step(model=model,
                                       dataloader=train_dataloader,
                                       loss_fn=loss_fn,
                                       optimizer=optimizer,
                                       device=device
                                      )

    test_loss, test_acc = test_step(model=model,
                                       dataloader=test_dataloader,
                                       loss_fn=loss_fn,
                                       device=device
                                    )

    # Print out what is happening
    print(f"Epoch: {epoch} | Train loss: {train_loss: .4f}, Train accuracy: {train_acc: .4f} | Test loss: {test_loss: .4f}, Test accuracy: {test_acc: .4f}")

    # Update results dictionary
    results["train_loss"].append(train_loss)
    results["train_acc"].append(train_acc)
    results["test_loss"].append(test_loss)
    results["test_acc"].append(test_acc)

  # Return the filled results at the end of the epochs loop
  return results

"""## Train and evaluate model_0"""

torch.manual_seed(42)
torch.cuda.manual_seed(42)

NUM_EPOCHS = 5

model_0 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(train_data.classes)).to(device)

# setup loss function and optimizer
loss_fn = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(params=model_0.parameters(),
                             lr=0.001) # default learning rate of Adam
                                       # default learning rates differ from one type of optimizer to another

# Start the timer
from timeit import default_timer as timer
start_time = timer()

# Train model_0
model_0_results = train(model=model_0,
                        train_dataloader=train_dataloader_simple,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_fn,
                        epochs=NUM_EPOCHS)

# End the timer
end_time = timer()
print(f"Train time: {end_time-start_time: .3f}")

model_0_results

"""## Plot the loss curve of model_0

"""

model_0_results.keys()

def plot_loss_curves(results: Dict[str, List[float]]):

  # Get the loss values of the results dict
  train_loss = results["train_loss"]
  test_loss = results["test_loss"]

  # Get the accuracy values of the results dict
  train_acc = results["train_acc"]
  test_acc = results["test_acc"]

  # Get the number of epochs
  epochs = range(len(results["train_loss"]))

  # Setup a plot
  plt.figure(figsize=(15, 7))

  # Plot the loss
  plt.subplot(1, 2, 1)
  plt.plot(epochs, train_loss, label="train_loss")
  plt.plot(epochs, test_loss, label="test_loss")
  plt.title("Loss")
  plt.xlabel("Epochs")
  plt.legend()


  # Plot the accuracy
  plt.subplot(1, 2, 2)
  plt.plot(epochs, train_acc, label="train_acc")
  plt.plot(epochs, test_acc, label="test_acc")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend()

plot_loss_curves(model_0_results)

"""## Ideal loss curve diagram

A loss curve is one of the best way to troubleshoot a model

1. Underfitting - When loss could be lower
2. Overfitting - Train is lower than the test
3. Just right - Train and test loss similar

Machine learning is all about finding the balance between underfitting and overfitting

## model_1 - TinyVGG with Data Augmentation
"""

# Create training transform with trivialaugment
from torchvision import transforms
train_transform_trivial = transforms.Compose(
    [
        transforms.Resize(size=(64,64)),
        transforms.TrivialAugmentWide(num_magnitude_bins=31),
        transforms.ToTensor()
    ]
)

test_transform_simple = transforms.Compose(
    [
        transforms.Resize(size=(64,64)),
        transforms.ToTensor()
    ]
)

# Create train and test datasets and dataloaders with DataAugmentation
from torchvision import datasets
train_data_augmented = datasets.ImageFolder(root=train_dir,
                                            transform=train_transform_trivial)

test_data_simple = datasets.ImageFolder(root=test_dir,
                                        transform=test_transform_simple)

# train_dir, train_transform_trivial, test_transform_simple
# train_data_augmented

# Turn datasets into dataloaders
import os
from torch.utils.data import DataLoader

BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

torch.manual_seed(42)

train_dataloader_augmented = DataLoader(dataset=train_data_augmented,
                                        batch_size=BATCH_SIZE,
                                        num_workers=NUM_WORKERS,
                                        shuffle=True)

test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                      batch_size=BATCH_SIZE,
                                      num_workers=NUM_WORKERS,
                                      shuffle=False)

# Construct and train model_1
torch.manual_seed(42)
model_1 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(train_data_augmented.classes)).to(device)



model_1

# Set random seeds
torch.manual_seed(42)
torch.cuda.manual_seed(42)

# Set the number of epochs
NUM_EPOCHS = 5

# Setup loss function
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_1.parameters(),
                             lr=0.001)

# Start the timer
from timeit import default_timer as timer
start_time = timer()

# Train model 1
model_1_results = train(model=model_1,
                        train_dataloader=train_dataloader_augmented,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_fn,
                        epochs=NUM_EPOCHS,
                        device=device)

# End the timer and print out how long it took
end_time = timer()
print(f"Total training time for model_1: {end_time-start_time:.3f} seconds")

model_1_results

## Plot the loss curves of model_1
plot_loss_curves(model_1_results)

## Compare model results

import pandas as pd

model_0_df = pd.DataFrame(model_0_results)
model_1_df = pd.DataFrame(model_1_results)

model_0_df

# setup a plot
plt.figure(figsize=(15,10))

# get number of epochs
epochs = range(len(model_0_df))

# plot train loss
plt.subplot(2,2,1)
plt.plot(epochs, model_0_df["train_loss"], label="Model_0")
plt.plot(epochs, model_1_df["train_loss"], label="Model_1")
plt.title('Train loss')
plt.xlabel("Epochs")
plt.legend()


# plot test loss
plt.subplot(2,2,2)
plt.plot(epochs, model_0_df["test_loss"], label="Model_0")
plt.plot(epochs, model_1_df["test_loss"], label="Model_1")
plt.title('Test loss')
plt.xlabel("Epochs")
plt.legend()


# plot train accuracy
plt.subplot(2,2,3)
plt.plot(epochs, model_0_df["train_acc"], label="Model_0")
plt.plot(epochs, model_1_df["train_acc"], label="Model_1")
plt.title('Train accuracy')
plt.xlabel("Epochs")
plt.legend()


# plot test accuracy
plt.subplot(2,2,4)
plt.plot(epochs, model_0_df["test_acc"], label="Model_0")
plt.plot(epochs, model_1_df["test_acc"], label="Model_1")
plt.title('Test accuracy')
plt.xlabel("Epochs")
plt.legend()

# Download custom image
import requests

# Setup custom image path
custom_image_path = data_path / "04-pizza-dad.jpeg"

# Download the image if it doesn't already exist
if not custom_image_path.is_file():
  with open(custom_image_path, "wb") as f:
    # When downloading from GitHub, need to use the "raw" file link
    request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg")
    print(f"Downloading {custom_image_path}...")
    f.write(request.content)
else:
  print(f"{custom_image_path} already exists, skipping download...")

str(custom_image_path)

import torchvision

# Read in custom image
custom_image_uint8 = torchvision.io.read_image(str(custom_image_path)) ## Need to resolve this
custom_image_path

import torchvision

# Read in custom image
custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))
print(f"Custom image tensor:\n {custom_image_uint8}")
print(f"Custom image shape: {custom_image_uint8.shape}")
print(f"Custom image datatype: {custom_image_uint8.dtype}")

plt.imshow(custom_image_uint8.permute(1,2,0));

## Making a prediction on a custom image with a trained PyTorch model

# Load the custom image and convert to float32
custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32) / 255
custom_image

# Create a transform pipeline to resize the image
from torchvision import transforms
custom_image_transform = transforms.Compose(
    [
        transforms.Resize(size=(64,64))
    ]
)

custom_image_transformed = custom_image_transform(custom_image)
custom_image.shape, custom_image_transformed.shape

plt.imshow(custom_image_transformed.permute(1,2,0))

custom_image.shape, custom_image_transformed.unsqueeze(0).shape

# This will error: no batch size
model_1.eval()
with torch.inference_mode():
  custom_image_pred = model_1(custom_image_transformed.to(device))

"""## To make a prediction on a custom image we had to:

1. Load the image and turn into tensor
2. Make sure the image was the same datatype as the model (torch.float32)
3. Make sure the image has the same shape as the data the model was trained on (3, 64, 64) with a batch size (1, 3, 64, 64)
4. Make sure the image was on the same device as our model
"""

## logits -> prediction probabilities

"""## Putting custom image prediction together: building a function

Ideal outcome - An image path is passsed to a function and have our model predict on that image and plot the image + prediction
"""

