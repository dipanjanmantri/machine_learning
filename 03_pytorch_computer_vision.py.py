# -*- coding: utf-8 -*-
"""03_pytorch_computer_vision_video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xQEVxrqMxMlcInQA0UEQ25qi3VDlVBQs

## PyTorch Computer Vision

# Computer vision libraries in PyTorch

* torchvision.datasets
* torchvision.models
* torchvision.transforms
* torch.utils.data.Dataset
* torch.utils.data.DataLoader
"""

# Import PyTorch
import torch
from torch import nn

# Import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor

# Import matplotlib for visualization
import matplotlib.pyplot as plt

# Check versions
print(torch.__version__)
print(torchvision.__version__)

import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
device

"""## Getting a dataset

The dataset is FashionMNIST
"""

# Setup training data
from torchvision import datasets
train_data = datasets.FashionMNIST(
    root="data", # where to download data to
    train=True, # do we want the training dataset?
    download=True, # do we want to download yes/no?
    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?
    target_transform=None # do we want to transform the labels? no
)



test_data = datasets.FashionMNIST(
    root="data", # where to download data to
    train=False, # do we want the training dataset?
    download=True, # do we want to download yes/no?
    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?
    target_transform=None # do we want to transform the labels? no
)

len(train_data), len(test_data)

# See the first training example
image, label = train_data[40000]
label

class_names = train_data.classes
class_names

class_to_idx = train_data.class_to_idx
class_to_idx

train_data.targets

# Check the shape of our image
print(f"Image shape: {image.shape} -> [color_channels, height, width]") # 1 means gray color scale, where 1 represents white and 0 is black
print(f"Image label: {class_names[label]}")

"""## Visualizing our data"""

import matplotlib.pyplot as plt
image, label = train_data[0]

print(f"Image shape: {image.shape}")
plt.imshow(image.squeeze()) # squeeze removes extra dimension
plt.title(class_names[label])

plt.imshow(image.squeeze(), cmap="gray")
plt.title(class_names[label])
plt.axis(False) # removes the axis

# plot more images
torch.manual_seed(42)
fig = plt.figure(figsize=(9,9))
rows, cols = 4, 4

for i in range(1, rows*cols+1):
  random_idx = torch.randint(1, len(train_data), size=[1]).item()
  img, label= train_data[random_idx]
  print(random_idx)
  fig.add_subplot(rows, cols, i)
  plt.imshow(img.squeeze(), cmap="gray")
  plt.title(class_names[label])
  plt.axis(False)

"""# Prepare DataLoader.

1. Right now the data is in the format of PyTorch datasets.

2. DataLoader turns datasets into Python iterable.

3. Turn data into batches.
   To make it more computationally efficient.
   It gives the neural network more chances to update its gradients per epoch.
                           
"""

from torch.utils.data import DataLoader

# setup batch-size hyperparameter
BATCH_SIZE=32

# turn datasets into interables (batches)
train_dataloader=DataLoader(dataset=train_data,
                            batch_size=BATCH_SIZE,
                            shuffle=True) # shuffle to remove order of the images

test_dataloader=DataLoader(dataset=test_data,
                            batch_size=BATCH_SIZE,
                            shuffle=False)

train_dataloader, test_dataloader

# Lets check out what we have created
print(f"Dataloaders: {train_dataloader, test_dataloader}")

len(train_dataloader), len(test_dataloader)

# Check what is inside the training_dataloader
train_features_batch, train_labels_batch = next(iter(train_dataloader)) # Assigns the next batch
train_features_batch.shape, train_labels_batch.shape

# Show a sample
random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()
img, label = train_features_batch[random_idx], train_labels_batch[random_idx]
plt.imshow(img.squeeze(), cmap="gray")
plt.title(class_names[label])
plt.axis(False)
print(f"Image size: {img.shape}")
print(f"Label: {label}, Label shape: {label.shape}")

"""# Model 0 - Build a baseline moel

1. When building a series of machine learning modeling experiments its the best practice to start with a baseline model.


"""

# Create a flatten layer
flatten_model=nn.Flatten()

# Get a single sample
x = train_features_batch[0]

# Flatten the sample
output = flatten_model(x) # perform forward pass

# Print out what happened
print(f"Shape before flattening: {x.shape}")
print(f"Shape after flattening: {output.shape}")

output.squeeze()

from torch import nn
class FashionMNISTModelV0(nn.Module):
  def __init__(self,
               input_shape:int,
               hidden_units:int,
               output_shape:int):
    super().__init__()
    self.layer_stack = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=input_shape, out_features=hidden_units),
        nn.Linear(in_features=hidden_units, out_features=output_shape)
    )


  def forward(self, x):
    return self.layer_stack(x)

torch.manual_seed(42)

# setup model with input parameters
model_0=FashionMNISTModelV0(
    input_shape=784,
    hidden_units=10, # how many units in the hidden layer
    output_shape=len(class_names) # one for every class
).to(device)


model_0

dummy_x=torch.rand([1,1,28,28]).to(device) # batch, color channels, height, width
model_0(dummy_x)

model_0.state_dict()

"""## Setup loss, optimizer and evaluation metrics
1. Loss function - nn.CrossEntropyLoss()
2. Optimizer - torch.optim.SGD()
3. Evaluation metric - Accuracy
"""

import requests
from pathlib import Path

# Download helper functions from Learn PyTorch repo
if Path("helper_functions.py").is_file():
  print("File exists")
else:
  print("downloading the file")
  request=requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open("helper_functions.py", "wb") as f:
    f.write(request.content)

# Import accuracy metric
from helper_functions import accuracy_fn

# setup loss function and optimizer
loss_fn=nn.CrossEntropyLoss()
optimizer=torch.optim.SGD(params=model_0.parameters(),
                          lr=0.1)

"""## Creating a function to time our experiments

Two of the main things to track are:

1. Model's performance (loss and accuracy values)
2. How fast it runs


"""

from timeit import default_timer as timer

def print_train_time(start:float,
                     end:float,
                     device:torch.device=None):
  # prints difference between start and end time
  total_time=end-start
  print(f"Train time on device: {device} is {total_time: .3f} seconds")
  return total_time

start_time=timer()
# some code ....
end_time=timer()

print_train_time(start=start_time, end=end_time, device="cpu")

"""### Creating a training loop and training a model on batches of data

1. Loop through epochs.
2. Loop through training batches, perform training steps, calculate the train loss per batch.
3. Loop through testing batches, perform testing steps, calculate the test loss per batch.
4. Print out what's happening.
5. Time it all (for fun).


"""

# Import tqdm for progress bar
from tqdm.auto import tqdm

# Set the seed and start the timer
torch.manual_seed(42)
train_time_start_on_cpu = timer()

# Set the number of epochs
epochs = 3

# Create a train and test loop
for epoch in tqdm(range(epochs)):
  print(f"Epoch: {epoch}\n-----------")
  ### Train
  train_loss = 0

  # Add a loop to loop the through training batches
  for batch, (X,y) in enumerate(train_dataloader):

    X, y = X.to(device), y.to(device)

    model_0.train()
    # 1. Forward Pass
    y_pred = model_0(X)

    # 2. Calculate loss per batch
    loss = loss_fn(y_pred, y)
    train_loss += loss # accumulate train loss

    # 3. Optimizer zero grad
    optimizer.zero_grad()

    # 4. Loss Backward
    loss.backward()

    # 5. Optimizer step
    optimizer.step()

    # Print out what's happening
    if batch % 400 == 0:
      print(f"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.")

  # Divide total train loss by length of train dataloader
  train_loss /= len(train_dataloader)


  ## Testing loop
  test_loss, test_acc = 0, 0

  model_0.eval()
  with torch.inference_mode():
    for X_test, y_test in test_dataloader:

      X_test, y_test = X_test.to(device), y_test.to(device)

      # 1. Forward pass
      test_pred = model_0(X_test)

      # 2. Calculate the loss (accumulatively)
      test_loss += loss_fn(test_pred, y_test)

      # 3. Calculate accuracy
      test_acc += accuracy_fn(y_true=y_test,
                              y_pred=test_pred.argmax(dim=1)) # Comparing labels to labels that is why test_pred.argmax(dim=1) is used to convert logits to labels


    # Calculate the test loss average per batch
    test_loss /= len(test_dataloader)

    # Calculate the test acc average per batch
    test_acc /= len(test_dataloader)

  # Print out what's happening
  print(f"\n Train loss: { train_loss: .4f} | Test loss: {test_loss: .4f} Test acc: {test_acc: .4f}%")


# Calculate the training time
train_time_end_on_cpu = timer()

total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,
                                            end=train_time_end_on_cpu,
                                            device=str(next(model_0.parameters()).device))

"""## Make predictions and get model_0 results"""

torch.manual_seed(42)
def eval_mode(model: torch.nn.Module,
              data_loader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module,
              accuracy_fn,
              device=device):


  # returns a dictionary containing the results of the model predicting on data_loader
  loss, acc = 0, 0
  model.eval()
  with torch.inference_mode():
    for X, y in tqdm(data_loader):
      # Make our data device agnostic
      X, y = X.to(device), y.to(device)

      # Make predictions
      y_pred = model(X)

      # Accumulate the loss and acc values per batch
      loss += loss_fn(y_pred, y)
      acc += accuracy_fn(y_true=y,
                         y_pred=y_pred.argmax(dim=1))

    # Scale loss and acc to find the average loss/acc per batch
    loss /= len(data_loader)
    acc /= len(data_loader)

  return {"model_name ": model.__class__.__name__, # only works when model was created with a class
          "model_loss ": loss.item(),
          "model_acc ": acc
          }

# Calculate model_0 results on test dataset
model_0_results = eval_mode(model=model_0,
                            data_loader=test_dataloader,
                            loss_fn=loss_fn,
                            accuracy_fn=accuracy_fn,
                            device=device)


model_0_results

"""## Setup a device agnostic code and run on GPU (if exists)"""

torch.cuda.is_available()

"""## Build a better model with non-linearity

"""

# Create a model with linear and non-linear layers
class FashionMNISTModelV1(nn.Module):
  def __init__(self,
               input_shape: int,
               hidden_units: int,
               output_shape: int):
    super().__init__()
    self.layer_stack = nn.Sequential(
        nn.Flatten(), # flatten input into a single vector
        nn.Linear(in_features=input_shape,
                  out_features=hidden_units),
        nn.ReLU(),
        nn.Linear(in_features=hidden_units,
                  out_features=output_shape),
        nn.ReLU()
    )

  def forward(self, x: torch.Tensor):
    return self.layer_stack(x)

# Create an instance of the model_1
torch.manual_seed(42)
model_1 = FashionMNISTModelV1(input_shape=784,
                              hidden_units=10,
                              output_shape=len(class_names)).to(device)

next(model_1.parameters()).device

!nvidia-smi

## Setup Loss, Optimizer and Evaluation metrics
from helper_functions import accuracy_fn
import torch.optim as optim

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(params=model_1.parameters(),lr=0.1)

"""Functionizing training and testing/evaluation loops

Create a function for:

1. training_loop - train_step()
2. testing_loop - test_step()
"""

def train_step(model: torch.nn.Module,
                data_loader: torch.utils.data.DataLoader,
                loss_fn: torch.nn.Module,
                optimizer: torch.optim,
                accuracy_fn,
                device: torch.device=device):

  train_loss, train_acc = 0, 0

  model.train()

  # Add a loop to loop the through training batches
  for batch, (X,y) in enumerate(data_loader):

    X, y = X.to(device), y.to(device)

    # 1. Forward Pass - outputs the raw logits from the model
    y_pred = model(X)

    # 2. Calculate loss per batch
    loss = loss_fn(y_pred, y)
    train_loss += loss # accumulate train loss
    train_acc += accuracy_fn(y_true=y,
                             y_pred=y_pred.argmax(dim=1))  # logits -> prediction labels
    # 3. Optimizer zero grad
    optimizer.zero_grad()

    # 4. Loss Backward
    loss.backward()

    # 5. Optimizer step
    optimizer.step()

  # Divide total train loss and acc by length of train dataloader
  train_loss /= len(data_loader)
  train_acc /= len(data_loader)

  print(f"Train loss: {train_loss: .4f} | Train acc: {train_acc: .2f}%")

def test_step(model: torch.nn.Module,
                data_loader: torch.utils.data.DataLoader,
                loss_fn: torch.nn.Module,
                accuracy_fn,
                device: torch.device=device):

  test_loss, test_acc = 0, 0

  model.eval()
  with torch.inference_mode():
    for X, y in data_loader:
      # Send the data to the target device
      X, y = X.to(device), y.to(device)

      # 1. Forward pass
      test_pred = model(X)

      # 2. Calculate the loss (accumulatively)
      test_loss += loss_fn(test_pred, y)

      # 3. Calculate accuracy
      test_acc += accuracy_fn(y_true=y,
                              y_pred=test_pred.argmax(dim=1)) # Comparing labels to labels that is why test_pred.argmax(dim=1) is used to convert logits to labels


    # Calculate the test loss average per batch
    test_loss /= len(data_loader)

    # Calculate the test acc average per batch
    test_acc /= len(data_loader)

    # Print out what's happening
    print(f"\n Test loss: {test_loss: .4f} | Test acc: {test_acc: .4f}%")

"""## Train and test model_1 for 3 epochs using train_step() and test_step()"""

model_0_results

total_train_time_model_0

# Import tqdm for progress bar
from tqdm.auto import tqdm

# Set the seed and start the timer
torch.manual_seed(42)
train_time_start_on_gpu = timer()

# Set the number of epochs
epochs = 3

# Import accuracy metric
from helper_functions import accuracy_fn

# setup loss function and optimizer
loss_fn=nn.CrossEntropyLoss()
optimizer=torch.optim.SGD(params=model_0.parameters(),
                          lr=0.1)


# Create a train and test loop
for epoch in tqdm(range(epochs)):
  print(f"Epoch: {epoch}\n-----------")

  train_step(model=model_1,
             data_loader=train_dataloader,
             loss_fn=loss_fn,
             optimizer=optimizer,
             accuracy_fn=accuracy_fn,
             device=device
            )

  test_step(model=model_1,
             data_loader=test_dataloader,
             loss_fn=loss_fn,
             accuracy_fn=accuracy_fn,
             device=device)


# Calculate the training time
train_time_end_on_gpu = timer()

total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,
                                            end=train_time_end_on_gpu,
                                            device=str(next(model_1.parameters()).device))

# Get model_1 results dictionary
model_1_results = eval_mode(model=model_1,
                            data_loader=test_dataloader,
                            loss_fn=loss_fn,
                            accuracy_fn=accuracy_fn)

model_1_results

"""## Build a Convolutional Neural Network (CNN)

1. CNNs has the capacity to find patterns in visual data.

Check out this resource - https://poloclub.github.io/cnn-explainer/

"""

# Create a convolutional neural network
class FashionMNISTModelV2(nn.Module):
  """
  Model architecture that replicates the TinyVGG
  model from CNN explainer website.
  """
  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
    super().__init__()
    self.conv_block_1 = nn.Sequential(
        # Create a conv layer - https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html
        nn.Conv2d(in_channels=input_shape,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1), # values we can set ourselves in our NN's are called hyperparameters
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*7*7, # there's a trick to calculating this...
                                                # 7*7 comes from Output shape of conv_block_2: torch.Size([1, 10, 7, 7])
                  out_features=output_shape)
    )

  def forward(self, x):
    x = self.conv_block_1(x)
    # print(f"Output shape of conv_block_1: {x.shape}")
    x = self.conv_block_2(x)
    # print(f"Output shape of conv_block_2: {x.shape}")
    x = self.classifier(x)
    # print(f"Output shape of classifier: {x.shape}")
    return x

torch.manual_seed(42)
model_2 = FashionMNISTModelV2(input_shape=1,
                              hidden_units=10,
                              output_shape=len(class_names)).to(device)

rand_image_tensor = torch.randn(size=(1, 28, 28))
rand_image_tensor.shape

# Pass image through model
model_2(rand_image_tensor.unsqueeze(0).to(device))

device

"""## Stepping through nn.Conv2d()"""

torch.manual_seed(42)

# Create a batch of images
images = torch.randn(size=(32,3,64,64))
test_image = images[0]

print(f"Images batch shape: {images.shape}")
print(f"Single image shape: {test_image.shape}")
print(f"Test image: {test_image}")

model_2.state_dict()

# Create a single Conv2d layer
conv_layer = nn.Conv2d(in_channels=3,
                       out_channels=10,
                       kernel_size=(3,3),
                       stride=1,
                       padding=1)

# Pass the data through the convolutional layer
conv_output = conv_layer(test_image.unsqueeze(0))
conv_output.shape

test_image.shape , test_image.unsqueeze(0).shape # adds a dimension the test_image shape

"""## Stepping through nn.MaxPool2d"""

# Print out the original image shape without unsqueeze
print(f"test image original shape: {test_image.shape}")
print(f"test image original shape with unsqueeze: {test_image.unsqueeze(0).shape}")


# Create a MaxPoolLayer2d
max_pool_layer = nn.MaxPool2d(kernel_size=(2,2))

# Pass data through the conv layer
test_image_through_conv = conv_layer(test_image.unsqueeze(0))
print(f"shape after passing through the conv layer: {test_image_through_conv.shape}")

# Pass data through MaxPool2d
test_image_through_conv_maxpool = max_pool_layer(test_image_through_conv)
print(f"shape after passing through the conv layer and maxpool: {test_image_through_conv_maxpool.shape}")

torch.manual_seed(42)

# create a random tensor
random_tensor = torch.randn(size=(1,1,2,2)) # order of values are batch_size, color_channels, height, width
print(f"Random tensor: {random_tensor}")
print(f"\n Random tensor shape: {random_tensor.shape}")

# create a maxpool2d
max_pool = nn.MaxPool2d(kernel_size=(2,2))

# pass the data through the maxpool
data_through_maxpool = max_pool(random_tensor)

# print shapes
print(f"maxpool tensor: {data_through_maxpool}")
print(f"\n shape before maxpool; {random_tensor.shape}")
print(f"\n shape after maxpool: {data_through_maxpool.shape}")

plt.imshow(image.squeeze(), cmap="gray")

rand_image_tensor = torch.randn(size=(1,28,28))
rand_image_tensor = rand_image_tensor.to(device)
rand_image_tensor.shape, device

model_2(rand_image_tensor.unsqueeze(0)).to(device)

# setup  a loss function and optimizer for model_2

from helper_functions import accuracy_fn

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_2.parameters(),
                            lr=0.1)

# use train_step() and test_step() for training and testing

torch.manual_seed(42)
torch.cuda.manual_seed(42)

# measure time
from timeit import default_timer as timer
train_time_start_model2 = timer()

# train and test model
epochs = 3
for epoch in tqdm(range(epochs)):
  print(f"epoch: {epoch}\n")
  train_step(model=model_2,
              data_loader=train_dataloader,
              loss_fn=loss_fn,
              optimizer=optimizer,
              accuracy_fn=accuracy_fn,
              device=device)
  test_step(model=model_2,
              data_loader=test_dataloader,
              loss_fn=loss_fn,
              accuracy_fn=accuracy_fn,
              device=device)


train_time_end_model2 = timer()
total_train_time_model_2 = print_train_time(start=train_time_start_model2,
                                            end=train_time_end_model2,
                                            device=device)

# get model_2 results
model_2_results = eval_mode(
    model=model_2,
    data_loader=test_dataloader,
    loss_fn=loss_fn,
    accuracy_fn=accuracy_fn,
    device=device
)

model_2_results

model_0_results

"""## compare model results and training time

"""

import pandas as pd
compare_results = pd.DataFrame([model_0_results,
                                model_1_results,
                                model_2_results])

compare_results

## Add training time to results comparison
compare_results["train_time"] = [total_train_time_model_0,
                                 total_train_time_model_1,
                                 total_train_time_model_2]

compare_results

print(compare_results.columns)

# Visualize our model results
compare_results.set_index("model_name ")["model_acc "].plot(kind="barh")
plt.xlabel("accuracy (%)")
plt.ylabel("model");

# Make and evaluate random predictions with the best model

def make_predictions(model: torch.nn.Module,
                     data: list,
                     device: torch.device = device):
  pred_probs = []
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      # prepare the sample
      sample = torch.unsqueeze(sample, dim=0).to(device)

      # forward pass - outputs raw logits
      pred_logit = model(sample)

      # logit -> pred probs
      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)

      # get pred_prob off the GPU
      pred_probs.append(pred_prob.cpu())


  # Stack the pred_probs and turn list into tensor
  return torch.stack(pred_probs)

test_data

import random
random.seed(42)
test_samples = []
test_labels = []

for sample, label in random.sample(list(test_data), k=9):
  test_samples.append(sample)
  test_labels.append(label)


# view the first sample shape
test_samples[0].shape

plt.imshow(test_samples[4].squeeze(), cmap="gray")
plt.title(class_names[test_labels[4]])

# Make predictions
pred_probs = make_predictions(model=model_2,
                              data=test_samples)

# View first two prediction probabilties
pred_probs[:2]

# Convert prediction probs to labels
pred_classes = pred_probs.argmax(dim=1)
pred_classes, test_labels

class_names[pred_classes[0]], class_names[test_labels[0]]

# Plot predictions
plt.figure(figsize=(9,9))
nrows=3
ncols=3

for i, sample in enumerate(test_samples):
  # Create subplot
  plt.subplot(nrows, ncols, i+1)

  # Plot the target image
  plt.imshow(sample.squeeze(), cmap="gray")

  # Find the prediction in text form
  pred_label = class_names[pred_classes[i]]

  # Get the truth label in text form
  truth_label = class_names[test_labels[i]]

  # Create a title for the plot
  title_text = f"Pred: {pred_label} | truth: {truth_label}"

  # Check for equality between pred and truth and change color of title text accordingly
  if pred_label == truth_label:
    plt.title(title_text, fontsize=10, c="g") # green
  else:
    plt.title(title_text, fontsize=10, c="r") # red

  plt.axis(False)

"""## Make a confusion matrix for further prediction evaluation

1. Make predictions with our trained model on the test dataset
2. Make a confusion matrix - https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html
3. Plot the confusion matrix - https://github.com/rasbt/mlxtend/tree/master

"""

# Import tqdm.auto
from tqdm.auto import tqdm

# 1. Make predictions with the trained model
y_preds = []
model_2.eval()
with torch.inference_mode():
  for X, y in tqdm(test_dataloader, desc="Making predictions..."):
    # Send the data and targets to target device
    X, y = X.to(device), y.to(device)

    # Forward pass
    y_logit = model_2(X)

    # Logits->pred_probs->pred_labels
    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)

    # Put predictions on cpu for evaluation
    y_preds.append(y_pred.cpu())


# Concatenate the list of predictions into a tensor
# print(y_preds)
y_pred_tensor = torch.cat(y_preds)
y_pred_tensor[:10]

len(y_pred_tensor)

!pip install torchmetrics

try:
  import torchmetrics, mlxtend
except:
  print("need to import")

torchmetrics.__version__, mlxtend.__version__

class_names

y_pred_tensor, len(y_pred_tensor), test_data,test_data.targets, len(test_data), len(test_data.targets)

from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

# Setup confusion instance and compare predictions to target
confmat = ConfusionMatrix(num_classes=len(class_names), task="multiclass")
confmat_tensor = confmat(preds=y_pred_tensor,
                         target=test_data.targets)
confmat_tensor

# Plot the confusion matrix
fix, ax = plot_confusion_matrix(
    conf_mat=confmat_tensor.numpy(), # matplotlib likes numpy
    class_names=class_names,
    figsize=(10,7)
)

! pip install Pathlib

# Save and load best performing model
from pathlib import Path

# Create model directory path
MODEL_PATH = Path("models")
MODEL_PATH.mkdir(parents=True,
                 exist_ok=True)

# Create model save
MODEL_NAME = "03_pytorch_computer_vision_model_2.pth"
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME

# Save the model state dict
print(f"Saving the newly created model: {MODEL_SAVE_PATH}")
torch.save(obj=model_2.state_dict(),
           f=MODEL_SAVE_PATH)

# Create a new instance
torch.manual_seed(42)
torch.cuda.manual_seed(42)

loaded_model_2 = FashionMNISTModelV2(input_shape=1,
                                     hidden_units=10,
                                     output_shape=len(class_names))

# Load the saved state_dict()
loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))

# Send the model to the target device
loaded_model_2 = loaded_model_2.to(device)

loaded_model_2

model_2_results

# Evaluate the loaded model
torch.manual_seed(42)
torch.cuda.manual_seed(42)

loaded_model_2_results = eval_mode(
    model=loaded_model_2,
    data_loader=test_dataloader,
    loss_fn=loss_fn,
    accuracy_fn=accuracy_fn
)

loaded_model_2_results

# Check if model results are close to each other
torch.isclose(torch.tensor(model_2_results["model_loss "]),
              torch.tensor(loaded_model_2_results["model_loss "]),
              atol=1e-04)