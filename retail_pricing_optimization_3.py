# -*- coding: utf-8 -*-
"""Retail_Pricing_Optimization_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vFqPyQN_YuV6GWIU0XA_TFtlRqhMylzg

## Start with a simple block, add complexity incrementally by assigning variables with different names instead of modifying the existing ones, then using the new variables to evaluate the performances of the models.

1. Make sure never modify or delete the variables, code that was a part of the simple block.
2. Always and always keep the simple block.
3. For debugging purpose comment out the simple block while adding complexity incrementally.
4. Do not add all the complexities to a single cell in colab, it will make it difficult to debug.
5. Add complexities to new cells, this will help in troubleshooting as it makes the code more modular.
6. Document every cell as much as possible so that if I need to troubleshoot after a long time, I can figure out quickly what the code is doing.
7. Always write clean and/or lean code.



## Document, document, document, document...................
"""

import pandas as pd
import torch
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from torch import nn
import numpy as np
from sklearn.preprocessing import LabelEncoder
from copy import deepcopy as dc

# Using different strategy to read the data
data_0 = pd.read_csv('shopping_trends.csv')
data_0 = data_0[['Age', 'Gender', 'Item', 'Location', 'Color', 'Season','Purchase_Amount']]
df = dc(data_0) # df is the dataframe, dc is the deepcopy library used to deepcopy data_0


features = ['Age', 'Gender', 'Item', 'Location', 'Color', 'Season']
# df = pd.DataFrame(df)

# Use LabelEncoder for categorical columns
label_encoder = LabelEncoder()

# Apply label encoding to each categorical column
df['Age'] = label_encoder.fit_transform(df['Age'])
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df['Item'] = label_encoder.fit_transform(df['Item'])
df['Location'] = label_encoder.fit_transform(df['Location'])
df['Color'] = label_encoder.fit_transform(df['Color'])
df['Season'] = label_encoder.fit_transform(df['Season'])



# Use OneHotEncoder to convert categorical columns to one-hot vectors
onehot_encoder = OneHotEncoder(sparse_output=False)

# Reshape the data to fit the one-hot encoder
df_reshaped = df.values.reshape(-1, 1)
#print(df_reshaped)

# Apply one-hot encoding
onehot_encoded = onehot_encoder.fit_transform(df_reshaped)
label_encoded = label_encoder.fit_transform(df_reshaped.ravel())
print(label_encoded)


# Inverse transform to get back the original labels
# original_data = label_encoder.inverse_transform(label_encoded)
# print(original_data)

# Convert to a PyTorch tensor
tensor_data = torch.tensor(label_encoded, dtype=torch.float32)
# print(tensor_data)

X = torch.tensor(df[features].values, dtype=torch.float32)
y = torch.tensor(df["Purchase_Amount"].values, dtype=torch.float32)

print(X[:6])
print(y[:6])
print(X.shape)
print(y.shape)

# Define DNN architecture
class DynamicPricingNet(nn.Module):
    def __init__(self, input_dim, hidden_dim,output_dim):
        super(DynamicPricingNet, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.relu(self.fc4(x))
        return x

model = DynamicPricingNet(6, 12, 1) # X.shape[1] is the input size
model

# Define optimizer and loss function
optimizer = torch.optim.Adam(model.parameters(),
                             lr=0.001)

loss_fn_l1 = nn.L1Loss()

loss_fn_mse = nn.MSELoss()

loss_fn_huber = nn.SmoothL1Loss(reduction= 'mean')


# An epoch is one loop through the data.....(this is a hyper-parameter because we set it ourselves)
epochs=10000


# Track different values
epoch_count=[]
loss_values=[]
eval_loss=[]




# Train the model
for epoch in range(epochs):
    # Forward pass
    model.train()
    # y_pred = model(X)
    y_pred = model(X)
    loss = loss_fn_huber(y_pred.unsqueeze(dim=0), y.view(1,3900,1))

    # Backward pass and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    ## Testing
    model.eval()

    with torch.inference_mode():
      eval_pred = model(X)
      eval_loss = loss_fn_huber(eval_pred.unsqueeze(0), y.view(1,3900,1))
      loss_values.append(loss)
      epoch_count.append(epoch)


    if epoch % 500 == 0:
      print(f"Epoch: {epoch} | Loss: {loss}")

new_features = [28,  1, 20, 49, 23,  2]


# Dynamic pricing function
def predict_price(new_features):
    new_data = torch.tensor(new_features, dtype=torch.float32)
    return model(new_data).item()

predict_price(new_features)